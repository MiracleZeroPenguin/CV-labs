{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.utils import shuffle\n",
    "import pylab\n",
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"./MNIST_data\"\n",
    "model_path=\"./model/\"\n",
    "log_path=\"./log/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载MINIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-f8c0b6ec9bb5>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(data_path,reshape=False)\n",
    "x_train,y_train=mnist.train.images,mnist.train.labels\n",
    "x_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17c3be49c48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im=mnist.train.images[3364]\n",
    "im=im.reshape(-1,28)\n",
    "pylab.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.image('input', x_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片预处理Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.pad(x_train, [(0,0),(2,2),(2,2),(0,0)], \"constant\")\n",
    "x_val = np.pad(x_val, [(0,0),(2,2),(2,2),(0,0)], \"constant\")\n",
    "x_test = np.pad(x_test, [(0,0),(2,2),(2,2),(0,0)], \"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=shuffle(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, shape=(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 独热码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehot=tf.one_hot(y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet(x):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    conv1_w = tf.Variable(tf.truncated_normal(shape=[5,5,1,6], mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_w, strides=[1,1,1,1], padding=\"VALID\") + conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    pool_1 = tf.nn.max_pool(conv1, ksize=[1,2,2,1],strides=[1,2,2,1], padding=\"VALID\")\n",
    "\n",
    "    conv2_w = tf.Variable(tf.truncated_normal(shape=[5,5,6,16], mean=mu, stddev=sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(pool_1, conv2_w, strides=[1,1,1,1], padding=\"VALID\") + conv2_b\n",
    "\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    pool_2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1],strides=[1,2,2,1], padding=\"VALID\")\n",
    "\n",
    "    fc1 = flatten(pool_2)\n",
    "    fc1_w = tf.Variable(tf.truncated_normal(shape=(400,120), mean=mu, stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(fc1, fc1_w)+fc1_b\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "\n",
    "    fc2_w = tf.Variable(tf.truncated_normal(shape=(120,84), mean=mu, stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1, fc2_w) + fc2_b\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    fc3_w = tf.Variable(tf.truncated_normal(shape=(84,10), mean=mu, stddev=sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_w) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000017C3BF19D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000017C3BF19D08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000017C3BF19D08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x0000017C3BF19D08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-12-83da88168a81>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_onehot, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, x_data, y_data, Batch_size, acc):\n",
    "    num_examples = len(x_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for begin in range(0, num_examples, Batch_size):\n",
    "        batch_x, batch_y = x_data[begin: begin+Batch_size], y_data[begin: begin+Batch_size]\n",
    "        accuracy = sess.run(acc, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy = total_accuracy + (accuracy*len(batch_x))\n",
    "    return total_accuracy/num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size=128\n",
    "Epochs = 10\n",
    "is_train=True\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_onehot, 1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar('loss',loss_operation)\n",
    "tf.summary.scalar('accuracy', acc)\n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "if not os.path.exists(log_path):\n",
    "    os.mkdir(log_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Start Training-------\n",
      "Epochs 1\n",
      "Validation Accuracy = 0.9694\n",
      "Epochs 2\n",
      "Validation Accuracy = 0.9792\n",
      "Epochs 3\n",
      "Validation Accuracy = 0.9818\n",
      "Epochs 4\n",
      "Validation Accuracy = 0.9874\n",
      "Epochs 5\n",
      "Validation Accuracy = 0.9876\n",
      "Epochs 6\n",
      "Validation Accuracy = 0.9854\n",
      "Epochs 7\n",
      "Validation Accuracy = 0.9874\n",
      "Epochs 8\n",
      "Validation Accuracy = 0.9892\n",
      "Epochs 9\n",
      "Validation Accuracy = 0.9872\n",
      "Epochs 10\n",
      "Validation Accuracy = 0.9880\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/Batch_size)\n",
    "    writer = tf.summary.FileWriter(log_path)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "    print(\"-------Start Training-------\")\n",
    "    for i in range(Epochs):\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        for j in range(total_batch):\n",
    "            begin = j * Batch_size\n",
    "            end = begin + Batch_size\n",
    "            # batch_x, batch_y = mnist.train.next_batch(Batch_size)\n",
    "            batch_x, batch_y = x_train[begin:end], y_train[begin:end]\n",
    "            _, summ1 = sess.run([training_operation,summ], feed_dict={x:batch_x, y:batch_y})\n",
    "            # writer.add_summary(summ1, i)\n",
    "            writer.add_summary(summ1, i * total_batch + j)\n",
    "        val_acc = evaluate(x, y, x_val, y_val, Batch_size, acc)\n",
    "        print(\"Epochs {}\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.4f}\".format(val_acc))\n",
    "        saver.save(sess, model_path+\"model.ckpt\")\n",
    "    print(\"model saved\")2\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Start Testing-------\n",
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt\n",
      "test_acc: 0.9883\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    total_batch = int(mnist.train.num_examples/Batch_size)\n",
    "    writer = tf.summary.FileWriter(log_path)\n",
    "    writer.add_graph(sess.graph)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "    print(\"-------Start Testing-------\")\n",
    "    model_file = tf.train.latest_checkpoint(model_path)\n",
    "    saver.restore(sess,model_file)\n",
    "    test_acc = sess.run(acc, feed_dict={x: x_test, y: y_test})\n",
    "    print('test_acc: {:.4f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
